18.3783783784, 14.5192307692, 18.04, 17.0, 15.7142857143, 17.7671232877, 18.9577464789, 18.2025316456,
16.0657894737, 17.4625, 18.0384615385, 15.7586206897, 16.625, 16.3404255319, 13.9130434783, 14.2526315789,
13.4485981308, 14.141025641, 15.5128205128, 14.0, 11.9285714286, 10.9583333333, 9.41379310345, 13.1568627451,
14.8767123288, 15.3442622951, 16.5849056604, 16.4230769231, 15.7727272727, 18.4358974359, 18.6507936508,
15.0428571429, 19.3018867925, 19.3157894737, 21.28, 17.7234042553, 16.8222222222, 17.5769230769, 16.9,
13.4307692308, 16.5818181818, 13.5531914894, 13.75, 13.1538461538, 11.7183098592, 13.25, 10.275, 14.170212766,
14.6545454545, 14.5614035088, 8.4375, 12.5909090909, 14.9897959184, 15.9787234043, 14.2592592593, 15.7325581395,
17.0505050505, 18.1714285714, 17.1325301205, 12.8382352941, 17.0350877193, 15.8113207547, 17.4, 16.9183673469,
16.4782608696, 14.3548387097, 13.5, 12.4745762712, 11.8085106383, 11.5689655172, 10.1960784314, 10.2352941176,
10.775862069, 13.512195122, 12.5526315789, 12.2564102564, 15.8387096774, 16.4814814815, 12.652173913),
nrow=5, ncol=28, byrow = T), type = "heatmap", colors = colorRamp(c("white", "firebrick3")))
p <- layout(p, title=layout$title, xaxis=layout$xaxis)
p
knitr::include_graphics("top20count.jpg")
knitr::include_graphics("Scatterplot.png")
library(magrittr)
library(stringr)
library(dplyr)
library(ggplot2)
library(tm)
library(wordcloud)
library(syuzhet)
library(tidytext)
library(tidyr)
library(igraph)
library(ggraph)
library(readr)
library(circlize)
library(reshape2)
lyrics <- read.csv('./data/taylor_swift_lyrics.csv')
lyrics$length <- str_count(lyrics$lyric,"\\S+")
length_df <- lyrics %>%
group_by(track_title) %>%
summarise(length = sum(length))
library(magrittr)
library(stringr)
library(dplyr)
library(ggplot2)
library(tm)
library(wordcloud)
library(syuzhet)
library(tidytext)
library(tidyr)
library(igraph)
library(ggraph)
library(readr)
library(circlize)
library(reshape2)
lyrics <- read.csv('./data/taylor_swift_lyrics.csv')
lyrics$length <- str_count(lyrics$lyric,"\\S+")
length_df <- lyrics %>%
group_by(track_title) %>%
summarise(length = sum(length))
length_df %>%
arrange(length) %>%
ggplot(length_df, aes(x=length)) +
geom_histogram(bins=30,aes(fill = ..count..)) +
geom_vline(aes(xintercept=mean(length)),
color="#FFFFFF", linetype="dashed", size=1) +
geom_density(aes(y=25 * ..count..),alpha=.2, fill="#1CCCC6") +
ylab("Count") + xlab ("Length") +
ggtitle("Distribution of word count") +
theme_minimal()
library(magrittr)
library(stringr)
library(dplyr)
library(ggplot2)
library(tm)
library(wordcloud)
library(syuzhet)
library(tidytext)
library(tidyr)
library(igraph)
library(ggraph)
library(readr)
library(circlize)
library(reshape2)
lyrics <- read.csv('./data/taylor_swift_lyrics.csv')
lyrics$length <- str_count(lyrics$lyric,"\\S+")
length_df <- lyrics %>%
group_by(track_title) %>%
summarise(length = sum(length))
length_df %>%
arrange(length) %>%
ggplot(length_df, aes(x=length)) +
geom_histogram(bins=30,aes(fill = ..count..)) +
geom_vline(aes(xintercept=mean(length)),
color="#FFFFFF", linetype="dashed", size=1) +
geom_density(aes(y=25 * ..count..),alpha=.2, fill="#1CCCC6") +
ylab("Count") + xlab ("Length") +
ggtitle("Distribution of word count") +
theme_minimal()
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(stringr)
library(dplyr)
library(ggplot2)
library(tm)
library(wordcloud)
library(syuzhet)
library(tidytext)
library(tidyr)
library(igraph)
library(ggraph)
library(readr)
library(circlize)
library(reshape2)
lyrics <- read.csv('./data/taylor_swift_lyrics.csv')
lyrics$length <- str_count(lyrics$lyric,"\\S+")
length_df <- lyrics %>%
group_by(track_title) %>%
summarise(length = sum(length))
length_df %>%
arrange(length) %>%
slice(1:10)
knitr::include_graphics("Scatterplot.png")
knitr::opts_chunk$set(echo = TRUE)
knitr::include_graphics("non_alphabetic_char_dist.png")
knitr::include_graphics("Pie1.png")
runApp()
library(shiny)
Apprin()
runApp()
setwd("C:/Users/hongx/Desktop/ANLY503/ProgrmmingForAnalyticsGroupProject-master/GroupProjectToSubmit/ProjectApp")
setwd("C:/Users/hongx/Desktop/ANLY503/ProgrmmingForAnalyticsGroupProject-master/GroupProjectToSubmit/ProjectApp")
runApp()
install.packages('rworldmap')
runApp()
install.packages('RMySQL')
runApp()
"C:\Program Files\MySQL\MySQL Server 5.5\bin\mysqld" --install
install.packages("httr")
install.packages("httr")
install.packages("httr")
install.packages("httr")
install.packages("httr")
install.packages("billboard")
install.packages("ggvis")
install.packages("spotifyr")
install.packages("miscTools")
runApp()
library(shiny)
runApp()
library(ggvis)
library(car)
install.packages("car")
library(shiny)
library(devtools)
library(spotifyr)
library(tidyverse)
library(dplyr)
library(billboard)
library(httr)
library(miscTools)
library(ggplot2)
library(car)
library(ggvis)
library(plotly)
top <- read.csv("Billboard_Top_1.csv")
for (i in 1:nrow(top)) {
if (top$year[i] < 1970) {
top$year[i] <- str_sub("1960-1969")
}else if (top$year[i] < 1980){
top$year[i] <- str_sub("1970-1979")
}else if (top$year[i] < 1990){
top$year[i] <- str_sub("1980-1989")
}else if (top$year[i] < 2000){
top$year[i] <- str_sub("1990-1999")
}else if (top$year[i] < 2010){
top$year[i] <- str_sub("2000-2009")
}else if (top$year[i] < 2019){
top$year[i] <- str_sub("2009-2018")
}
}
danceability <- ggplot(top, aes(top$danceability,top$valence)) +
geom_point(aes(color = as.factor(year))) +
geom_smooth(se = FALSE) +
labs(title = "Danceability vs. Valence")
runApp()
setwd("C:/Users/hongx/Desktop/ANLY503/Final-Project-master/Final_Project")
runApp()
top <- read.csv("Billboard_Top_1.csv")
for (i in 1:nrow(top)) {
if (top$year[i] < 1970) {
top$year[i] <- str_sub("1960-1969")
}else if (top$year[i] < 1980){
top$year[i] <- str_sub("1970-1979")
}else if (top$year[i] < 1990){
top$year[i] <- str_sub("1980-1989")
}else if (top$year[i] < 2000){
top$year[i] <- str_sub("1990-1999")
}else if (top$year[i] < 2010){
top$year[i] <- str_sub("2000-2009")
}else if (top$year[i] < 2019){
top$year[i] <- str_sub("2009-2018")
}
}
runApp()
runApp()
runApp()
runApp()
install.packages('shinydashboard')
runApp()
runApp()
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(stringr)
library(dplyr)
library(ggplot2)
library(tm)
library(wordcloud)
library(syuzhet)
library(tidytext)
library(tidyr)
library(igraph)
library(ggraph)
library(readr)
library(circlize)
library(reshape2)
lyrics <- read.csv('./taylor_swift_lyrics.csv')
View(lyrics)
View(lyrics)
lyrics <- read.csv('./taylor_swift_lyrics.csv')
lyrics$length <- str_count(lyrics$lyric,"\\S+")
View(lyrics)
View(lyrics)
lyrics <- read.csv('./taylor_swift_lyrics.csv')
lyrics$length <- str_count(lyrics$lyric,"\\S+")
length_df <- lyrics %>%
group_by(track_title) %>%
summarise(length = sum(length))
View(length_df)
View(length_df)
library(magrittr)
library(stringr)
library(dplyr)
library(ggplot2)
library(tm)
library(wordcloud)
library(syuzhet)
library(tidytext)
library(tidyr)
library(igraph)
library(ggraph)
library(readr)
library(circlize)
library(reshape2)
library("tm")
library("wordcloud")
lyrics_text <- lyrics$lyric
lyrics_text <- lyrics$lyric
lyrics_text<- gsub('[[:punct:]]+', '', lyrics_text)
lyrics_text<- gsub("([[:alpha:]])\1+", "", lyrics_text)
#creating a text corpus
docs <- Corpus(VectorSource(lyrics_text))
# Converting the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Removing english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# creating term document matrix
tdm <- TermDocumentMatrix(docs)
# defining tdm as matrix
m <- as.matrix(tdm)
# getting word counts in decreasing order
word_freqs = sort(rowSums(m), decreasing=TRUE)
# creating a data frame with words and their frequencies
lyrics_wc_df <- data.frame(word=names(word_freqs), freq=word_freqs)
lyrics_wc_df <- lyrics_wc_df[1:300,]
View(lyrics_wc_df)
View(lyrics_wc_df)
ty_sentiment <- get_nrc_sentiment((lyrics_text))
# Dataframe with cumulative value of the sentiments
sentimentscores<-data.frame(colSums(ty_sentiment[,]))
# Dataframe with sentiment and score as columns
names(sentimentscores) <- "Score"
sentimentscores <- cbind("sentiment"=rownames(sentimentscores),sentimentscores)
rownames(sentimentscores) <- NULL
View(sentimentscores)
View(sentimentscores)
View(sentimentscores)
View(sentimentscores)
lyrics$lyric <- as.character(lyrics$lyric)
tidy_lyrics <- lyrics %>%
unnest_tokens(word,lyric)
song_wrd_count <- tidy_lyrics %>% count(track_title)
lyric_counts <- tidy_lyrics %>%
left_join(song_wrd_count, by = "track_title") %>%
rename(total_words=n)
lyric_sentiment <- tidy_lyrics %>%
inner_join(get_sentiments("nrc"),by="word")
lyric_sentiment %>%
count(word,sentiment,sort=TRUE) %>%
group_by(sentiment)%>%top_n(n=10) %>%
ungroup()
View(lyric_sentiment)
View(lyric_sentiment)
lyric_sentiment %>%
count(track_title,sentiment,sort=TRUE) %>%
group_by(sentiment) %>%
top_n(n=5)
View(lyric_sentiment)
View(lyric_sentiment)
year_emotion <- lyric_sentiment %>%
filter(!sentiment %in% c("positive", "negative")) %>%
count(sentiment, year) %>%
group_by(year, sentiment) %>%
summarise(sentiment_sum = sum(n)) %>%
ungroup()
View(year_emotion)
View(year_emotion)
View(lyric_sentiment)
View(lyric_sentiment)
lyrics <- read.csv('./all_singers.csv')
lyrics$length <- str_count(lyrics$lyric,"\\S+")
length_df <- lyrics %>%
group_by(track_title) %>%
summarise(length = sum(length))
lyrics_text <- lyrics$lyric
lyrics_text<- gsub('[[:punct:]]+', '', lyrics_text)
lyrics_text<- gsub("([[:alpha:]])\1+", "", lyrics_text)
#creating a text corpus
docs <- Corpus(VectorSource(lyrics_text))
# Converting the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Removing english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# creating term document matrix
tdm <- TermDocumentMatrix(docs)
# defining tdm as matrix
m <- as.matrix(tdm)
# getting word counts in decreasing order
word_freqs = sort(rowSums(m), decreasing=TRUE)
# creating a data frame with words and their frequencies
lyrics_wc_df <- data.frame(word=names(word_freqs), freq=word_freqs)
lyrics_wc_df <- lyrics_wc_df[1:300,]
lyrics <- read.csv('./all_singers.csv')
lyrics$length <- str_count(lyrics$lyric,"\\S+")
length_df <- lyrics %>%
group_by(track_title) %>%
summarise(length = sum(length))
lyrics_text <- lyrics$lyric
lyrics_text<- gsub('[[:punct:]]+', '', lyrics_text)
lyrics_text<- gsub("([[:alpha:]])\1+", "", lyrics_text)
#creating a text corpus
docs <- Corpus(VectorSource(lyrics_text))
# Converting the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Removing english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# creating term document matrix
tdm <- TermDocumentMatrix(docs)
# defining tdm as matrix
m <- as.matrix(tdm)
ty_sentiment <- get_nrc_sentiment((lyrics_text))
restartR()
library(magrittr)
library(stringr)
library(dplyr)
library(ggplot2)
library(tm)
library(wordcloud)
library(syuzhet)
library(tidytext)
library(tidyr)
library(igraph)
library(ggraph)
library(readr)
library(circlize)
library(reshape2)
library("tm")
library("wordcloud")
lyrics <- read.csv('./all_singers.csv')
lyrics$length <- str_count(lyrics$lyric,"\\S+")
length_df <- lyrics %>%
group_by(track_title) %>%
summarise(length = sum(length))
lyrics <- read.csv('./all_singers.csv')
lyrics$length <- str_count(lyrics$lyric,"\\S+")
length_df <- lyrics %>%
group_by(track_title) %>%
summarise(length = sum(length))
lyrics_text <- lyrics$lyric
lyrics_text<- gsub('[[:punct:]]+', '', lyrics_text)
lyrics_text<- gsub("([[:alpha:]])\1+", "", lyrics_text)
ty_sentiment <- get_nrc_sentiment((lyrics_text))
View(ty_sentiment)
View(ty_sentiment)
# Dataframe with cumulative value of the sentiments
sentimentscores<-data.frame(colSums(ty_sentiment[,]))
# Dataframe with sentiment and score as columns
names(sentimentscores) <- "Score"
sentimentscores <- cbind("sentiment"=rownames(sentimentscores),sentimentscores)
rownames(sentimentscores) <- NULL
lyrics$lyric <- as.character(lyrics$lyric)
tidy_lyrics <- lyrics %>%
unnest_tokens(word,lyric)
song_wrd_count <- tidy_lyrics %>% count(track_title)
lyric_counts <- tidy_lyrics %>%
left_join(song_wrd_count, by = "track_title") %>%
rename(total_words=n)
lyric_sentiment <- tidy_lyrics %>%
inner_join(get_sentiments("nrc"),by="word")
lyric_sentiment %>%
count(word,sentiment,sort=TRUE) %>%
group_by(sentiment)%>%top_n(n=10) %>%
ungroup()
View(lyric_sentiment)
View(lyric_sentiment)
lyric_sentiment %>%
count(track_title,sentiment,sort=TRUE) %>%
group_by(sentiment) %>%
top_n(n=5)
View(lyric_sentiment)
View(lyric_sentiment)
View(lyrics)
View(lyrics)
year_emotion <- lyric_sentiment %>%
filter(!sentiment %in% c("positive", "negative")) %>%
count(sentiment, year) %>%
group_by(year, sentiment) %>%
summarise(sentiment_sum = sum(n)) %>%
ungroup()
circos.clear()
#Setting the gap size
circos.par(gap.after = c(rep(6, length(unique(year_emotion[[1]])) - 1), 15,
rep(6, length(unique(year_emotion[[2]])) - 1), 15))
chordDiagram(year_emotion, grid.col = grid.col, transparency = .2)
grid.col = c("2006" = "#E69F00", "2008" = "#56B4E9", "2010" = "#009E73", "2012" = "#CC79A7", "2014" = "#D55E00", "2017" = "#00D6C9", "anger" = "grey", "anticipation" = "grey", "disgust" = "grey", "fear" = "grey", "joy" = "grey", "sadness" = "grey", "surprise" = "grey", "trust" = "grey")
year_emotion <- lyric_sentiment %>%
filter(!sentiment %in% c("positive", "negative")) %>%
count(sentiment, year) %>%
group_by(year, sentiment) %>%
summarise(sentiment_sum = sum(n)) %>%
ungroup()
circos.clear()
#Setting the gap size
circos.par(gap.after = c(rep(6, length(unique(year_emotion[[1]])) - 1), 15,
rep(6, length(unique(year_emotion[[2]])) - 1), 15))
chordDiagram(year_emotion, grid.col = grid.col, transparency = .2)
View(year_emotion)
View(year_emotion)
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(stringr)
library(dplyr)
library(ggplot2)
library(tm)
library(wordcloud)
library(syuzhet)
library(tidytext)
library(tidyr)
library(igraph)
library(ggraph)
library(readr)
library(circlize)
library(reshape2)
library("tm")
library("wordcloud")
lyrics <- read.csv('./all_singers.csv')
lyrics$length <- str_count(lyrics$lyric,"\\S+")
length_df <- lyrics %>%
group_by(track_title) %>%
summarise(length = sum(length))
lyrics_text <- lyrics$lyric
lyrics_text<- gsub('[[:punct:]]+', '', lyrics_text)
lyrics_text<- gsub("([[:alpha:]])\1+", "", lyrics_text)
ty_sentiment <- get_nrc_sentiment((lyrics_text))
# Dataframe with cumulative value of the sentiments
sentimentscores<-data.frame(colSums(ty_sentiment[,]))
# Dataframe with sentiment and score as columns
names(sentimentscores) <- "Score"
sentimentscores <- cbind("sentiment"=rownames(sentimentscores),sentimentscores)
rownames(sentimentscores) <- NULL
lyrics$lyric <- as.character(lyrics$lyric)
tidy_lyrics <- lyrics %>%
unnest_tokens(word,lyric)
song_wrd_count <- tidy_lyrics %>% count(track_title)
lyric_counts <- tidy_lyrics %>%
left_join(song_wrd_count, by = "track_title") %>%
rename(total_words=n)
lyric_sentiment <- tidy_lyrics %>%
inner_join(get_sentiments("nrc"),by="word")
lyric_sentiment %>%
count(word,sentiment,sort=TRUE) %>%
group_by(sentiment)%>%top_n(n=10) %>%
ungroup()
lyric_sentiment %>%
count(track_title,sentiment,sort=TRUE) %>%
group_by(sentiment) %>%
top_n(n=5)
grid.col = c("2006" = "#E69F00", "2008" = "#56B4E9", "2010" = "#009E73", "2012" = "#CC79A7", "2014" = "#D55E00", "2017" = "#00D6C9", "anger" = "grey", "anticipation" = "grey", "disgust" = "grey", "fear" = "grey", "joy" = "grey", "sadness" = "grey", "surprise" = "grey", "trust" = "grey")
year_emotion <- lyric_sentiment %>%
filter(!sentiment %in% c("positive", "negative")) %>%
count(sentiment, year) %>%
group_by(year, sentiment) %>%
summarise(sentiment_sum = sum(n)) %>%
ungroup()
circos.clear()
#Setting the gap size
circos.par(gap.after = c(rep(6, length(unique(year_emotion[[1]])) - 1), 15,
rep(6, length(unique(year_emotion[[2]])) - 1), 15))
chordDiagram(year_emotion, grid.col = grid.col, transparency = .2)
title("Relationship between emotion and song's year of release")
View(year_emotion)
View(year_emotion)
View(lyrics)
View(lyrics)
View(lyric_sentiment)
View(lyric_sentiment)
write.csv(year_emotion, file = "year_emotion.csv")
write.csv(year_emotion, file = "year_emotion.csv")
write.csv(lyric_sentiment, file = "lyric_sentiment.csv")
